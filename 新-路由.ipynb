{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de38618-76a0-401b-946f-f8d0c26b334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import find_objects\n",
    "import torchio as tio\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from configparser import ConfigParser\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from dataset import ACDCDataset, PairwiseAugmentor\n",
    "\n",
    "# 配置参数\n",
    "CLASS_MAP = {'NOR':0, 'DCM':1, 'HCM':2, 'MINF':3, 'RV':4}\n",
    "TARGET_SHAPE = (200, 200, 80)\n",
    "TARGET_SPACING = 1.25  # mm\n",
    "AUG_FACTOR = 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b75098-8873-409f-975f-a9abf788f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps3D(nn.Module):\n",
    "    def __init__(self, in_channels=256, caps_dim=4, kernel_size=3, stride=2):\n",
    "        super().__init__()\n",
    "        self.caps_dim = caps_dim\n",
    "        self.out_caps = in_channels // caps_dim  # 主胶囊数量\n",
    "        self.conv = nn.Conv3d(in_channels, self.out_caps * caps_dim, \n",
    "                            kernel_size, stride=stride, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        out = self.conv(x)  # [B, out_caps*caps_dim, D, H, W]\n",
    "        \n",
    "        # 重塑维度：分离胶囊维度和特征维度\n",
    "        out = out.view(batch_size, self.out_caps, self.caps_dim,\n",
    "                      out.size(-3), out.size(-2), out.size(-1))  # [B, out_caps, caps_dim, D, H, W]\n",
    "        \n",
    "        # 调整维度顺序并展平空间维度\n",
    "        out = out.permute(0, 3, 4, 5, 1, 2).contiguous()  # [B, D, H, W, out_caps, caps_dim]\n",
    "        spatial_flatten = out.size(1)*out.size(2)*out.size(3)  # p = D*H*W\n",
    "        return out.view(batch_size, spatial_flatten, self.out_caps, self.caps_dim)  # [B, p, i, m]\n",
    "\n",
    "class ConvCaps3D(nn.Module):\n",
    "    def __init__(self, in_caps, out_caps, in_dim, out_dim, num_routing=3):\n",
    "        super().__init__()\n",
    "        self.num_routing = num_routing\n",
    "        self.W = nn.Parameter(torch.Tensor(in_caps, out_caps, in_dim, out_dim))  # [i, j, m, n]\n",
    "        nn.init.orthogonal_(self.W)\n",
    "\n",
    "    def dynamic_routing(self, u):\n",
    "        \"\"\"全局动态路由（合并空间位置）\"\"\"\n",
    "        batch_size, p, i, m = u.size()  # 输入u形状: [B, p, i, m]\n",
    "        device = u.device\n",
    "        \n",
    "        # 合并空间位置与输入胶囊维度 [B, p, i, m] -> [B, p*i, m]\n",
    "        u_combined = u.view(batch_size, p * i, m)\n",
    "        \n",
    "        # 计算预测向量 [B, p*i, m] × [i, j, m, n] -> [B, p*i, j, n]\n",
    "        u_hat = torch.einsum('bkm,ijmn->bkjn', u_combined, self.W)  # 修正后的einsum方程\n",
    "        \n",
    "        # 初始化路由logits [B, p*i, j]\n",
    "        b = torch.zeros(batch_size, p * i, self.W.size(1)).to(device)\n",
    "        \n",
    "        for _ in range(self.num_routing):\n",
    "            # 计算耦合系数 [B, p*i, j]\n",
    "            c = F.softmax(b, dim=-1)\n",
    "            \n",
    "            # 加权求和 [B, j, n]\n",
    "            s = torch.einsum('bkj,bkjn->bjn', c, u_hat)\n",
    "            \n",
    "            # 非线性压缩\n",
    "            v = self.squash(s)\n",
    "            \n",
    "            # 路由协议更新（训练时）\n",
    "            if self.training and _ < self.num_routing-1:\n",
    "                delta_b = torch.einsum('bjn,bkjn->bkj', v, u_hat)\n",
    "                b = b + delta_b\n",
    "        \n",
    "        return v  # 输出 [B, j, n]\n",
    "\n",
    "    def squash(self, input_tensor):\n",
    "        norm = torch.norm(input_tensor, dim=-1, keepdim=True)\n",
    "        scale = norm**2 / (1 + norm**2)\n",
    "        return scale * input_tensor / (norm + 1e-8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dynamic_routing(x)\n",
    "\n",
    "\n",
    "class EFGatedAttention(nn.Module):\n",
    "    def __init__(self, caps_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, caps_dim),\n",
    "            nn.Sigmoid()  # 输出[0,1]区间\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(caps_dim)\n",
    "\n",
    "    def forward(self, capsules, ef):\n",
    "        batch_size, p = capsules.size(0), capsules.size(1)\n",
    "        \n",
    "        gate = self.gate_net(ef.unsqueeze(1))  # [B, caps_dim]\n",
    "        gate = gate.view(batch_size, 1, 1, -1)  # 对齐胶囊维度\n",
    "        \n",
    "        gated_caps = capsules * gate  # 特征维度缩放\n",
    "        return self.layer_norm(gated_caps + capsules)  # 残差连接增强稳定性\n",
    "\n",
    "class Caps3DNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv3d = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 256, kernel_size=9, stride=3),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Dropout3d(0.2)\n",
    "        )\n",
    "        \n",
    "        # 初级胶囊层（输出[B, p, 64, 4]）\n",
    "        self.primary_caps = PrimaryCaps3D(in_channels=256, caps_dim=4)\n",
    "        \n",
    "        # EF门控注意力模块\n",
    "        self.ef_gate = EFGatedAttention(caps_dim=4)\n",
    "        \n",
    "        # 数字胶囊层\n",
    "        self.digit_caps = ConvCaps3D(\n",
    "            in_caps=64,\n",
    "            out_caps=num_classes,\n",
    "            in_dim=4,\n",
    "            out_dim=8\n",
    "        )\n",
    "        \n",
    "        # 分类器\n",
    "        self.classifier = nn.Linear(num_classes*8, num_classes)\n",
    "\n",
    "    def forward(self, x, ef):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 图像特征处理\n",
    "        x = self.conv3d(x)\n",
    "        primary_caps = self.primary_caps(x)  # [B, p, 64, 4]\n",
    "        \n",
    "        # 应用EF门控\n",
    "        gated_caps = self.ef_gate(primary_caps, ef)  # 维度保持[B, p, 64, 4]\n",
    "        \n",
    "        # 动态路由\n",
    "        caps_output = self.digit_caps(gated_caps)  # [B, num_classes, 8]\n",
    "        \n",
    "        return self.classifier(caps_output.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31318e73-78d9-42e5-bcbe-f1568e337e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing results file found. Starting fresh.\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202335/1876048004.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Test Accuracy: 23.33%\n",
      "\n",
      "Current 5-Fold CV Results: [0.23333333333333334]\n",
      "Average Accuracy: 23.33% (±0.00%)\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Early stopping at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202335/1876048004.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Test Accuracy: 21.67%\n",
      "\n",
      "Current 5-Fold CV Results: [0.23333333333333334, 0.21666666666666667]\n",
      "Average Accuracy: 22.50% (±0.83%)\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Early stopping at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202335/1876048004.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Test Accuracy: 48.33%\n",
      "\n",
      "Current 5-Fold CV Results: [0.23333333333333334, 0.21666666666666667, 0.48333333333333334]\n",
      "Average Accuracy: 31.11% (±12.20%)\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Early stopping at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202335/1876048004.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Test Accuracy: 33.33%\n",
      "\n",
      "Current 5-Fold CV Results: [0.23333333333333334, 0.21666666666666667, 0.48333333333333334, 0.3333333333333333]\n",
      "Average Accuracy: 31.67% (±10.61%)\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Early stopping at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202335/1876048004.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Test Accuracy: 50.00%\n",
      "\n",
      "Current 5-Fold CV Results: [0.23333333333333334, 0.21666666666666667, 0.48333333333333334, 0.3333333333333333, 0.5]\n",
      "Average Accuracy: 35.33% (±11.99%)\n",
      "\n",
      "=== Final Results ===\n",
      "5-Fold CV Results: [0.23333333333333334, 0.21666666666666667, 0.48333333333333334, 0.3333333333333333, 0.5]\n",
      "Average Accuracy: 35.33% (±11.99%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "\n",
    "if __name__ == '__main__':  # 确保在主模块中设置\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "\n",
    "start_fold = 0  # 可修改为需要开始的折数 (0-4)\n",
    "results_file = '新-路由.json'\n",
    "CUSTOM_PREFIX = \"新-路由\"\n",
    "\n",
    "# 尝试加载已有的结果 - 添加空文件处理\n",
    "fold_results = []\n",
    "if os.path.exists(results_file):\n",
    "    try:\n",
    "        with open(results_file, 'r') as f:\n",
    "            file_content = f.read().strip()\n",
    "            if file_content:  # 检查文件是否非空\n",
    "                fold_results = json.loads(file_content)\n",
    "                print(f\"Loaded existing results: {fold_results}\")\n",
    "            else:\n",
    "                print(\"Results file exists but is empty. Starting fresh.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Warning: Results file contains invalid JSON. Starting fresh.\")\n",
    "        fold_results = []\n",
    "else:\n",
    "    print(\"No existing results file found. Starting fresh.\")\n",
    "\n",
    "# 训练流程修改\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for inputs, labels, ef in loader:\n",
    "        inputs, labels, ef = inputs.to(device), labels.to(device), ef.float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, ef)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())  # 使用extend代替append\n",
    "        all_labels.extend(labels.cpu().numpy()) # 转换为numpy数组\n",
    "    \n",
    "    return running_loss/len(loader), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, ef in loader:\n",
    "            inputs, labels, ef = inputs.to(device), labels.to(device), ef.float().to(device)\n",
    "            \n",
    "            outputs = model(inputs, ef)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())   # 修改为extend\n",
    "            val_labels.extend(labels.cpu().numpy())  # 修改为extend\n",
    "    \n",
    "    return val_loss/len(loader.dataset), accuracy_score(val_labels, val_preds)\n",
    "\n",
    "\n",
    "# 五折交叉验证修改版\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_cases = [d for d in Path('心力衰竭/database/training').glob('patient*') if d.is_dir()] + \\\n",
    "            [d for d in Path('心力衰竭/database/testing').glob('patient*') if d.is_dir()]\n",
    "all_labels = []  # 存储每个病例的标签\n",
    "\n",
    "# 收集每个病例的标签\n",
    "for case in all_cases:\n",
    "    # 创建临时数据集实例（不需要变换）\n",
    "    _, label, _ = ACDCDataset([case], phase='train')[0]\n",
    "    all_labels.append(label)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(all_cases, all_labels)):\n",
    "    print(f\"\\n=== Fold {fold+1}/5 ===\")\n",
    "    \n",
    "    # 划分训练验证集和测试集\n",
    "    train_val_cases = [all_cases[i] for i in train_val_idx]\n",
    "    test_cases = [all_cases[i] for i in test_idx]\n",
    "    \n",
    "    # 从训练验证集中提取标签用于再分层\n",
    "    train_val_labels = [all_labels[i] for i in train_val_idx]\n",
    "    \n",
    "    # 在训练验证集内部进行分层划分 (75%训练, 25%验证)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_idx, val_idx in sss.split(train_val_cases, train_val_labels):\n",
    "        train_cases = [train_val_cases[i] for i in train_idx]\n",
    "        val_cases = [train_val_cases[i] for i in val_idx]\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = ACDCDataset(train_cases, phase='train')\n",
    "    val_dataset = ACDCDataset(val_cases, phase='val')    # 从训练集划分的验证集\n",
    "    test_dataset = ACDCDataset(test_cases, phase='val')  # 独立测试集\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "    \n",
    "    # 模型初始化（保持原有实现不变）\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Caps3DNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=5)\n",
    "    \n",
    "    # 初始化跟踪变量\n",
    "    best_acc = 0.0  # 只跟踪最佳准确率\n",
    "    best_loss = 10\n",
    "    best_model_path = f\"{CUSTOM_PREFIX}_fold{fold}_best.pth\"\n",
    "    final_model_path = f\"{CUSTOM_PREFIX}_fold{fold}_last.pth\"\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)  # 使用新验证集\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # 动态保存最佳模型（只保留最佳准确率版本）\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "        \n",
    "        # 早停判断（基于验证损失）\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= 10:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    fold_results.append(test_acc)  # 记录测试集准确率\n",
    "    print(f\"Fold {fold+1} Test Accuracy: {test_acc:.2%}\")    \n",
    "    \n",
    "    # 确保最终模型保存（即使早停也保存最后达到的epoch）\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(fold_results, f)\n",
    "    print(f\"\\nCurrent 5-Fold CV Results: {fold_results}\")\n",
    "    print(f\"Average Accuracy: {np.mean(fold_results):.2%} (±{np.std(fold_results):.2%})\")\n",
    "\n",
    "# 输出结果（保持原有实现不变）\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        final_results = json.load(f)\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"5-Fold CV Results: {final_results}\")\n",
    "print(f\"Average Accuracy: {np.mean(final_results):.2%} (±{np.std(final_results):.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
