{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eda3e26-6bc8-40f2-82fa-dd6de37723a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import find_objects\n",
    "import torchio as tio\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from configparser import ConfigParser\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from Fdataset import ACDCDataset, PairwiseAugmentor\n",
    "\n",
    "# 配置参数\n",
    "CLASS_MAP = {'NOR':0, 'DCM':1, 'HCM':2, 'MINF':3, 'RV':4}\n",
    "TARGET_SHAPE = (200, 200, 80)\n",
    "TARGET_SPACING = 1.25  # mm\n",
    "AUG_FACTOR = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e776b95-b46e-4c60-b41c-e5788c45a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D全卷积网络（FCN），专为医学3D图像分类设计\n",
    "    特点：结构简单、计算效率高，适合小样本3D医疗图像分类\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, in_channels=1, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 编码器部分（3个下采样模块）\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 第1个下采样模块\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 第2个下采样模块\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 第3个下采样模块\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 全局池化和分类头\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((1, 1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入形状: (B, 1, 200, 200, 80)\n",
    "        x = self.encoder(x)  # 输出形状: (B, 128, 25, 25, 10)\n",
    "        x = self.classifier(x)  # 输出形状: (B, 5)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33b127-c495-4ac9-80b0-20eeb4025965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing results file found. Starting fresh.\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "\n",
    "if __name__ == '__main__':  # 确保在主模块中设置\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "\n",
    "start_fold = 0  # 可修改为需要开始的折数 (0-4)\n",
    "results_file = '新-3DFCN.json'\n",
    "CUSTOM_PREFIX = \"新-3DFCN\"\n",
    "\n",
    "# 尝试加载已有的结果 - 添加空文件处理\n",
    "fold_results = []\n",
    "if os.path.exists(results_file):\n",
    "    try:\n",
    "        with open(results_file, 'r') as f:\n",
    "            file_content = f.read().strip()\n",
    "            if file_content:  # 检查文件是否非空\n",
    "                fold_results = json.loads(file_content)\n",
    "                print(f\"Loaded existing results: {fold_results}\")\n",
    "            else:\n",
    "                print(\"Results file exists but is empty. Starting fresh.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Warning: Results file contains invalid JSON. Starting fresh.\")\n",
    "        fold_results = []\n",
    "else:\n",
    "    print(\"No existing results file found. Starting fresh.\")\n",
    "\n",
    "# 训练流程修改\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())  # 使用extend代替append\n",
    "        all_labels.extend(labels.cpu().numpy()) # 转换为numpy数组\n",
    "    \n",
    "    return running_loss/len(loader), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())   # 修改为extend\n",
    "            val_labels.extend(labels.cpu().numpy())  # 修改为extend\n",
    "    \n",
    "    return val_loss/len(loader.dataset), accuracy_score(val_labels, val_preds)\n",
    "\n",
    "\n",
    "# 五折交叉验证修改版\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_cases = [d for d in Path('心力衰竭/database/training').glob('patient*') if d.is_dir()] + \\\n",
    "            [d for d in Path('心力衰竭/database/testing').glob('patient*') if d.is_dir()]\n",
    "all_labels = []  # 存储每个病例的标签\n",
    "\n",
    "# 收集每个病例的标签\n",
    "for case in all_cases:\n",
    "    # 创建临时数据集实例（不需要变换）\n",
    "    _, label = ACDCDataset([case], phase='train')[0]\n",
    "    all_labels.append(label)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(all_cases, all_labels)):\n",
    "    print(f\"\\n=== Fold {fold+1}/5 ===\")\n",
    "    \n",
    "    # 划分训练验证集和测试集\n",
    "    train_val_cases = [all_cases[i] for i in train_val_idx]\n",
    "    test_cases = [all_cases[i] for i in test_idx]\n",
    "    \n",
    "    # 从训练验证集中提取标签用于再分层\n",
    "    train_val_labels = [all_labels[i] for i in train_val_idx]\n",
    "    \n",
    "    # 在训练验证集内部进行分层划分 (75%训练, 25%验证)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_idx, val_idx in sss.split(train_val_cases, train_val_labels):\n",
    "        train_cases = [train_val_cases[i] for i in train_idx]\n",
    "        val_cases = [train_val_cases[i] for i in val_idx]\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = ACDCDataset(train_cases, phase='train')\n",
    "    val_dataset = ACDCDataset(val_cases, phase='val')    # 从训练集划分的验证集\n",
    "    test_dataset = ACDCDataset(test_cases, phase='val')  # 独立测试集\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "    \n",
    "    # 模型初始化（保持原有实现不变）\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FCN3D().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=5)\n",
    "    \n",
    "    # 初始化跟踪变量\n",
    "    best_acc = 0.0  # 只跟踪最佳准确率\n",
    "    best_loss = 10\n",
    "    best_model_path = f\"{CUSTOM_PREFIX}_fold{fold}_best.pth\"\n",
    "    final_model_path = f\"{CUSTOM_PREFIX}_fold{fold}_last.pth\"\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)  # 使用新验证集\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # 动态保存最佳模型（只保留最佳准确率版本）\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "        \n",
    "        # 早停判断（基于验证损失）\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= 10:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    fold_results.append(test_acc)  # 记录测试集准确率\n",
    "    print(f\"Fold {fold+1} Test Accuracy: {test_acc:.2%}\")    \n",
    "    \n",
    "    # 确保最终模型保存（即使早停也保存最后达到的epoch）\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(fold_results, f)\n",
    "    print(f\"\\nCurrent 5-Fold CV Results: {fold_results}\")\n",
    "    print(f\"Average Accuracy: {np.mean(fold_results):.2%} (±{np.std(fold_results):.2%})\")\n",
    "\n",
    "# 输出结果（保持原有实现不变）\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        final_results = json.load(f)\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"5-Fold CV Results: {final_results}\")\n",
    "print(f\"Average Accuracy: {np.mean(final_results):.2%} (±{np.std(final_results):.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
